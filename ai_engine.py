"""
BananaDB AI åˆ†æžå¼•æ“Ž
ä½¿ç”¨ Google Gemini 2.0 Flash Vision é€†å‘å·¥ç¨‹æç¤ºè©ž
"""
import os
import json
from typing import Dict, Any
import google.generativeai as genai
from dotenv import load_dotenv


# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è¨­å®š Gemini API
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("âŒ éŒ¯èª¤ï¼šæœªè¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")

genai.configure(api_key=GEMINI_API_KEY)


# System Prompt for Banana Pro é¢¨æ ¼åˆ†æž
BANANA_PRO_SYSTEM_PROMPT = """You are an expert in the 'Banana Pro' Stable Diffusion model. Analyze the uploaded image.

Extract or reverse-engineer the Positive Prompt (English). Focus on lighting, camera angle, and art style.
Translate the prompt into descriptive Traditional Chinese (Taiwan usage).
Suggest a standard Negative Prompt for this style.
Generate 3-5 relevant tags.

Return strict JSON format:
{
  "positive_prompt": "...",
  "positive_prompt_zh": "...",
  "negative_prompt": "...",
  "tags": ["tag1", "tag2", "tag3"]
}

IMPORTANT: Your response must be ONLY valid JSON. Do not include any markdown code blocks or explanations."""


def translate_prompt(text: str) -> Dict[str, str]:
    """
    è‡ªå‹•åµæ¸¬ä¸¦ç¿»è­¯ prompt
    - çŸ­ prompt: å®Œæ•´ç¿»è­¯
    - é•· prompt (>1000å­—): ä¿ç•™åŽŸæ–‡ + ç”Ÿæˆä¸­æ–‡æ‘˜è¦
    
    Args:
        text: è¦ç¿»è­¯çš„æ–‡å­—
    
    Returns:
        åŒ…å« 'english' å’Œ 'chinese' çš„å­—å…¸
    """
    try:
        import re
        
        # è¶…é•· promptï¼šä¿ç•™åŽŸæ–‡ + ç”Ÿæˆä¸­æ–‡æ‘˜è¦
        if len(text) > 1000:
            print(f"ðŸ“„ Prompt è¼ƒé•· ({len(text)} å­—å…ƒ)ï¼Œç”Ÿæˆä¸­æ–‡æ‘˜è¦")
            
            has_chinese = bool(re.search(r'[\u4e00-\u9fff]', text))
            
            if has_chinese:
                print("âž¡ï¸ åµæ¸¬åˆ°ä¸­æ–‡ï¼Œä¿ç•™åŽŸæ–‡")
                return {'english': '', 'chinese': text}
            
            # ç”Ÿæˆä¸­æ–‡æ‘˜è¦
            try:
                model = genai.GenerativeModel('gemini-2.0-flash')
                summary_prompt = f"""è«‹ç”¨ç°¡æ½”çš„ç¹é«”ä¸­æ–‡ç¸½çµé€™å€‹ AI åœ–ç‰‡ç”ŸæˆæŒ‡ä»¤ï¼ˆç´„150å­—å…§ï¼‰ï¼ŒåŒ…å«ï¼š
- ä¸»é¡Œæˆ–ä¸»è¦å…§å®¹
- é—œéµè¦–è¦ºå…ƒç´ 
- é¢¨æ ¼æˆ–æ°›åœ

æŒ‡ä»¤å…§å®¹ï¼ˆå‰2000å­—å…ƒï¼‰ï¼š
{text[:2000]}

åªè¼¸å‡ºç¹é«”ä¸­æ–‡æ‘˜è¦ï¼Œä¸è¦å¼•è™Ÿæˆ–å…¶ä»–æ ¼å¼ã€‚"""

                response = model.generate_content(summary_prompt)
                chinese_summary = response.text.strip()
                
                # æ¸…ç†æ ¼å¼
                chinese_summary = chinese_summary.replace('"', '').replace('`', '').replace('*', '').strip()
                if chinese_summary.startswith('```'):
                    lines = chinese_summary.split('\n')
                    chinese_summary = '\n'.join(lines[1:-1]) if len(lines) > 2 else chinese_summary
                chinese_summary = chinese_summary.strip()
                
                print(f"âœ… æ‘˜è¦ç”Ÿæˆ: {chinese_summary[:80]}...")
                return {'english': text, 'chinese': chinese_summary}
                
            except Exception as e:
                print(f"âš ï¸ æ‘˜è¦ç”Ÿæˆå¤±æ•—: {e}")
                import traceback
                traceback.print_exc()
                return {'english': text, 'chinese': 'ï¼ˆPrompt éŽé•·ï¼Œæ‘˜è¦ç”Ÿæˆå¤±æ•—ï¼‰'}
        
        # æ­£å¸¸é•·åº¦ï¼šå®Œæ•´ç¿»è­¯
        print(f"ðŸ”„ é–‹å§‹ç¿»è­¯ ({len(text)} å­—å…ƒ)")
        model = genai.GenerativeModel('gemini-2.0-flash')
        
        prompt = f"""ç¿»è­¯é€™æ®µæ–‡å­—ï¼š

{text}

è¦å‰‡ï¼š
- è‹±æ–‡ â†’ ç¹é«”ä¸­æ–‡ï¼ˆå°ç£ç”¨èªžï¼‰
- ç°¡é«”ä¸­æ–‡ â†’ ä¿æŒåŽŸæ¨£ï¼Œç¿»è­¯æˆè‹±æ–‡
- ç¹é«”ä¸­æ–‡ â†’ ä¿æŒåŽŸæ¨£ï¼Œç¿»è­¯æˆè‹±æ–‡

åªè¼¸å‡º JSONï¼š
{{"english": "...", "chinese": "..."}}"""

        response = model.generate_content(prompt)
        response_text = response.text.strip()
        
        # æ¸…ç† markdown
        for marker in ["```json", "```"]:
            if response_text.startswith(marker):
                response_text = response_text[len(marker):].strip()
        if response_text.endswith("```"):
            response_text = response_text[:-3].strip()
        
        # æå– JSON
        json_match = re.search(r'\{[^{}]*"english"[^{}]*"chinese"[^{}]*\}', response_text, re.DOTALL)
        if json_match:
            response_text = json_match.group(0)
        
        result = json.loads(response_text)
        english = result.get('english', '').strip()
        chinese = result.get('chinese', '').strip()
        
        if english or chinese:
            print(f"âœ… ç¿»è­¯æˆåŠŸ")
            return {'english': english or text, 'chinese': chinese}
        
        raise ValueError("Translation empty")
        
    except Exception as e:
        print(f"âŒ ç¿»è­¯å¤±æ•—: {type(e).__name__}: {e}")
        import re
        has_chinese = bool(re.search(r'[\u4e00-\u9fff]', text))
        return {'english': '', 'chinese': text} if has_chinese else {'english': text, 'chinese': ''}


def analyze_image(image_path: str, context_text: str = "") -> Dict[str, Any]:
    """
    ä½¿ç”¨ Gemini 2.0 Flash Vision åˆ†æžåœ–ç‰‡ä¸¦é€†å‘å·¥ç¨‹æç¤ºè©ž
    
    Args:
        image_path: åœ–ç‰‡æª”æ¡ˆè·¯å¾‘
        context_text: é¡å¤–çš„ä¸Šä¸‹æ–‡è³‡è¨Šï¼ˆé¸å¡«ï¼‰
    
    Returns:
        åŒ…å« positive_prompt, positive_prompt_zh, negative_prompt, tags çš„å­—å…¸
    """
    try:
        # ä½¿ç”¨ Gemini 2.0 Flash æ¨¡åž‹ï¼ˆç©©å®šç‰ˆæœ¬ï¼Œæ”¯æ´è¦–è¦ºåˆ†æžï¼‰
        model = genai.GenerativeModel('gemini-2.0-flash')
        
        # ä½¿ç”¨ PIL è®€å–ä¸¦ä¸Šå‚³åœ–ç‰‡ï¼ˆè‡ªå‹•è™•ç†å„ç¨®æ ¼å¼ï¼‰
        from PIL import Image
        image = Image.open(image_path)
        
        # æº–å‚™æç¤ºè©ž
        prompt_parts = [BANANA_PRO_SYSTEM_PROMPT]
        if context_text:
            prompt_parts.append(f"\nAdditional context: {context_text}")
        
        # å‘¼å« Gemini APIï¼ˆç›´æŽ¥å‚³å…¥ PIL Image ç‰©ä»¶ï¼‰
        response = model.generate_content(
            [prompt_parts[0], image] + (prompt_parts[1:] if len(prompt_parts) > 1 else [])
        )
        
        # è§£æž JSON å›žæ‡‰
        response_text = response.text.strip()
        
        # ç§»é™¤å¯èƒ½çš„ Markdown ç¨‹å¼ç¢¼å€å¡Šæ¨™è¨˜
        if response_text.startswith("```json"):
            response_text = response_text[7:]
        if response_text.startswith("```"):
            response_text = response_text[3:]
        if response_text.endswith("```"):
            response_text = response_text[:-3]
        response_text = response_text.strip()
        
        # è§£æž JSON
        result = json.loads(response_text)
        
        # é©—è­‰å¿…è¦æ¬„ä½
        required_fields = ["positive_prompt", "positive_prompt_zh", "negative_prompt", "tags"]
        for field in required_fields:
            if field not in result:
                result[field] = "" if field != "tags" else []
        
        # ç¢ºä¿ tags æ˜¯é™£åˆ—
        if not isinstance(result["tags"], list):
            result["tags"] = []
        
        print(f"âœ… AI åˆ†æžå®Œæˆ: {image_path}")
        return result
        
    except json.JSONDecodeError as e:
        print(f"âš ï¸ JSON è§£æžéŒ¯èª¤: {e}")
        print(f"åŽŸå§‹å›žæ‡‰: {response_text}")
        # å›žå‚³é è¨­å€¼
        return {
            "positive_prompt": "Unable to analyze image",
            "positive_prompt_zh": "ç„¡æ³•åˆ†æžåœ–ç‰‡",
            "negative_prompt": "low quality, blurry",
            "tags": ["error"]
        }
    
    except Exception as e:
        print(f"âŒ AI åˆ†æžå¤±æ•—: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        # å›žå‚³é è¨­å€¼
        return {
            "positive_prompt": "Error during analysis",
            "positive_prompt_zh": "åˆ†æžéŽç¨‹ç™¼ç”ŸéŒ¯èª¤",
            "negative_prompt": "low quality, blurry",
            "tags": ["error"]
        }


if __name__ == "__main__":
    # æ¸¬è©¦åˆ†æžåŠŸèƒ½ï¼ˆéœ€è¦å¯¦éš›åœ–ç‰‡æª”æ¡ˆï¼‰
    import sys
    if len(sys.argv) > 1:
        test_image = sys.argv[1]
        result = analyze_image(test_image)
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        print("ç”¨æ³•: python ai_engine.py <åœ–ç‰‡è·¯å¾‘>")
